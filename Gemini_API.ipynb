{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# step-1 Importing libraries\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from google import genai\n"
      ],
      "metadata": {
        "id": "nlvZOr54qfvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step -2 Call API\n",
        "GOOGLE_API_KEY = \"<your API Key>\" # your API Key"
      ],
      "metadata": {
        "id": "DkOJ33vcpW1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configurations\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "oWlxvjjspP04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model calling\n",
        "response = client.models.generate_content(\n",
        "  model=\"gemini-2.0-flash\",\n",
        "  contents=['What is AI in three sentences'])\n",
        "\n"
      ],
      "metadata": {
        "id": "kSLZEujppdps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k7nkhqFjO3E",
        "outputId": "a362e1b1-800b-4a19-e5b3-cbeee015cf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial intelligence (AI) involves creating computer systems that can perform tasks that typically require human intelligence. These tasks include learning, problem-solving, decision-making, and understanding language. AI aims to enable machines to simulate, augment, and even surpass human cognitive abilities in various domains.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "\n",
        "Welcome to AI long term course\n",
        "{AI_result}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def college_friend(doubt,template):\n",
        "  prompt = f\"\"\"Act like a student friendly application where a user will ask a question to you as doubt and answer the doubt with your knowlege and fill the details in template given to\n",
        "  and provide answers.\n",
        "  doubt : {doubt}\n",
        "  template : {template}\n",
        "\n",
        "  Answer the question {doubt} and fill the template. I don't want any commentry gets added to my results\n",
        "  \"\"\"\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[prompt]\n",
        ")\n",
        "\n",
        "  return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "Dd78N7HCHAeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doubt = input(\"Ask any question .!\")\n",
        "print(college_friend(doubt,template))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trz__0IgJDJm",
        "outputId": "74ebc00c-317e-4651-887f-89a0c188cfa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask any question .!What are the boarders of USA\n",
            "Welcome to AI long term course\n",
            "\n",
            "{AI_result}\n",
            "\n",
            "The United States of America shares land borders with two countries:\n",
            "\n",
            "*   **Canada:** To the north.\n",
            "*   **Mexico:** To the south.\n",
            "\n",
            "Additionally, the USA has maritime borders with Russia (in the Bering Strait), Cuba, and the Bahamas.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requirement = \"I want to apply for a leave due to medical emenrgency from 2nd may to 15th may\"\n",
        "template = f\"\"\"\n",
        "TO\n",
        "The HoD,\n",
        "Dear Sir,\n",
        "\n",
        "<Body of the letter, AI result>\n",
        "\n",
        "From\n",
        "Yaswanth\n",
        "\n",
        "\"\"\"\n",
        "prompt = f\"\"\"\n",
        "\n",
        "I wanted you to act as my E-mail buddy, you have to help me in writing the body of the letter based on my {requirement},\n",
        "I am writing this mail to my HoD, so use a professional language and respectable statements. You should only provide me the body of the letter,\n",
        "I am having an email template with me {template}. Replace <Body of the letter, AI result> with your generated e-mail body.\n",
        "I don't want any commentry or explanations gets added to my results\n",
        "\"\"\"\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[prompt]\n",
        ")\n",
        "print(response.text)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0hBjnEopfXC",
        "outputId": "f2b63a76-ca42-49bd-c1f9-deb0dd0e18fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TO \n",
            "The HoD,\n",
            "Dear Sir, \n",
            "\n",
            "Subject: Leave of Absence Request - [Your Name]\n",
            "\n",
            "Dear [HoD's Name],\n",
            "\n",
            "I am writing to respectfully request a leave of absence from my duties from May 2nd to May 15th, 2024, due to a medical emergency.\n",
            "\n",
            "I understand this may cause some inconvenience, and I apologize for any disruption this may cause. I will do my best to prepare for my absence and ensure a smooth handover of my responsibilities before my leave commences. I will also be available remotely for urgent matters, if needed.\n",
            "\n",
            "I will provide a medical certificate upon my return.\n",
            "\n",
            "Thank you for your consideration and understanding.\n",
            "\n",
            "\n",
            "From\n",
            "Yaswanth\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tTbDPe6EpsmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt intializing..\n",
        "question = input(\"Enter your question.!\")\n",
        "prompt = f\"\"\"\n",
        "you are a Data science expert, you can answer any question related to Data science\n",
        "question is : {question}\n",
        "please answer the question\n",
        "\"\"\"\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "aiYOC1AypkWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccd180f-faa0-4d5c-9748-c9c05e313971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question.!What is ML.?\n",
            "\n",
            "you are a Data science expert, you can answer any question related to Data science \n",
            "question is : What is ML.?\n",
            "please answer the question\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function building ..\n",
        "\n",
        "def answer_bot(question):\n",
        "    prompt = f\"\"\"\n",
        "    you are a Data science expert, you can answer any question which are related to Data science otherwise don't provide ant answer\n",
        "    instead mention Sorry, I can't answer this\n",
        "    question is : {question}\n",
        "    please answer the question\n",
        "    For Example :\n",
        "    Question : What is Microprocessor\n",
        "    AI : Sorry, I can't answer this\n",
        "    Question : What is a Supervised ML .?\n",
        "    AI : Yes I can Answer this ...\n",
        "    Question : What is Data.?\n",
        "    AI : Yes I can Answer this <provide your answer> ...\n",
        "    I Only want a direct answer no other commentry or explanation.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[prompt]\n",
        ")\n",
        "    return response.text\n",
        "\n",
        "question = input(\"enter question : \")\n",
        "print(answer_bot(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndOT-vWtiqba",
        "outputId": "1784ec2d-83bb-4c44-9360-fc230b54ec97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter question : What is K-means algorithm in 2 lines\n",
            "AI : Yes I can Answer this \n",
            "The K-means algorithm is an unsupervised learning method used to cluster data points into K distinct groups based on their proximity to cluster centroids. It iteratively assigns data points to the nearest centroid and updates the centroids based on the mean of the assigned data points until convergence.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#response\n",
        "question = input(\"Enter your question.!\")\n",
        "prompt = f\"\"\"\n",
        "you are a computer science expert, you can answer any question related to computer science based on the question\n",
        "question is : {question}\n",
        "please answer the question\n",
        "\"\"\"\n",
        "print(prompt)\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[prompt])"
      ],
      "metadata": {
        "id": "VVMI30b4SZu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d331dde2-39de-43e2-af50-e272dbaac093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question.!What is Physics\n",
            "\n",
            "you are a computer science expert, you can answer any question related to computer science based on the question\n",
            "question is : What is Physics\n",
            "please answer the question\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pricing calculations"
      ],
      "metadata": {
        "id": "pMn4HDXtoMYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njaG0FaLp14S",
        "outputId": "8b2feaa6-5235-498f-b550-bef608cffdac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cache_tokens_details=None cached_content_token_count=None candidates_token_count=745 candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=745)] prompt_token_count=34 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=34)] thoughts_token_count=None tool_use_prompt_token_count=None tool_use_prompt_tokens_details=None total_token_count=779 traffic_type=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata.candidates_token_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03SI06_HRwYF",
        "outputId": "16bd0c28-5d3f-48df-d9a6-9fdd12f8cfca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata.prompt_token_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwPEoafCRwVv",
        "outputId": "aa0b5f35-c9d9-40c1-ee47-5caf136aa551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.usage_metadata.total_token_count)"
      ],
      "metadata": {
        "id": "W9POvMtUShpH",
        "outputId": "12658178-b0bf-4270-9561-89313a4a287a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(57/1000000)*0.10"
      ],
      "metadata": {
        "id": "HSLj_EIlSkyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4290636-7fc1-41bb-e1c0-41ecd195dec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.7000000000000005e-06"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploring Text & Image Generation\n",
        "\n",
        "Text Generation with LLMs\n",
        "\n",
        "- Prompt Engineering – Crafting better inputs for\n",
        "AI models.\n",
        "- Fine-tuning – Customizing an AI model for\n",
        "specific use cases.\n",
        "- AI Text Applications – Chatbots, Summarization,\n",
        "Story Writing."
      ],
      "metadata": {
        "id": "PaCPo4qaqrn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "SdqmT1NBe7_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat bot application\n",
        "from google import genai\n",
        "\n",
        "def chat_with_gemini(user_input, model=\"gemini-2.0-flash\"): # Pass model as a parameter\n",
        "    #configurations\n",
        "    client = genai.Client(api_key='AIzaSyCTFhlWag6uYf4i18FaT5kQvZg8oHepJQk') # Replace with your API Key\n",
        "    response = client.models.generate_content(\n",
        "        model=model,  # Use the model parameter\n",
        "        contents=[user_input]\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# Simulate a conversation\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in ['exit', 'quit']:\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    else:\n",
        "        bot_response = chat_with_gemini(user_input)\n",
        "        print(f\"Gemini Bot: {bot_response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5teUnAvzrHI-",
        "outputId": "aac72432-af4e-4187-ac81-8805f443d27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: Hi\n",
            "Gemini Bot: Hi there! How can I help you today?\n",
            "\n",
            "You: What is democracy rate in USA 2023\n",
            "Gemini Bot: There are various organizations that attempt to measure and rank the state of democracy around the world, and they often come up with different scores and rankings. Here are a few examples for the USA in 2023:\n",
            "\n",
            "*   **The Economist Intelligence Unit's Democracy Index:** In the 2023 report, the U.S. was classified as a \"flawed democracy\" with a score of 7.85 out of 10.\n",
            "\n",
            "*   **Freedom House:** Freedom House's 2023 report gave the U.S. a \"Freedom Score\" of 83 out of 100, classifying it as \"Free.\"\n",
            "\n",
            "*   **V-Dem Institute:** V-Dem's 2023 report ranked the U.S. 42nd out of 178 countries.\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizations:\n",
        "from google import genai\n",
        "\n",
        "# configurations\n",
        "client = genai.Client(api_key='AIzaSyCTFhlWag6uYf4i18FaT5kQvZg8oHepJQk')  # Replace with your API Key\n",
        "model = \"gemini-2.0-flash\"\n",
        "\n",
        "# Function for summarizing text\n",
        "def summarize_text(text, model=model):  # Pass model as a parameter\n",
        "    prompt = f\"Summarize the following text in telugu language:\\n\\n{text}\\n\\nSummary:\"\n",
        "    response = client.models.generate_content(  # Call generate_content on the client object\n",
        "        model=model,  # Use the provided model\n",
        "        contents=[prompt]\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# Example text for summarization\n",
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is intelligence demonstrated by machines, in contrast to the natural intelligence displayed by humans and animals.\n",
        "Leading AI textbooks define the field as the study of \"intelligent agents\": any device that perceives its environment and takes actions that maximize its chance of successfully achieving its goals.\n",
        "Colloquially, the term \"artificial intelligence\" is often used to describe machines (or computers) that mimic \"cognitive\" functions that humans associate with the human mind, such as \"learning\" and \"problem solving\".\n",
        "\"\"\"\n",
        "\n",
        "# Summarize the text\n",
        "summary = summarize_text(text)\n",
        "print(\"Summary:\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ezwA1RArHLt",
        "outputId": "ba7e9183-f08f-4bd6-ceb6-e806b62e9c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary: సారాంశం:\n",
            "\n",
            "కృత్రిమ మేధస్సు (Artificial Intelligence - AI) అనేది మనుషులు, జంతువులలో ఉండే సహజ మేధస్సుకు విరుద్ధంగా, యంత్రాలు ప్రదర్శించే తెలివితేటలు. ఈ రంగంలో, యంత్రాలు తమ పరిసరాలను గ్రహించి, తమ లక్ష్యాలను సాధించడానికి అనుగుణంగా పనిచేస్తాయి. సాధారణంగా, కృత్రిమ మేధస్సు అంటే నేర్చుకోవడం, సమస్యలను పరిష్కరించడం వంటి మానసిక సామర్థ్యాలను అనుకరించే యంత్రాలు లేదా కంప్యూటర్లు.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83IDy_PXrHOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Zero-shot Learning – AI generates text without\n",
        "training.\n",
        "- Few-shot Learning – AI improves with small\n",
        "examples."
      ],
      "metadata": {
        "id": "udi6Mhjqr6YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Zero-shot learning means that AI can perform a task without needing to see examples of that specific task. It can generalize from what it already knows and figure out the solution on its own."
      ],
      "metadata": {
        "id": "Upvxhprpr9XW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Few-shot learning is the idea that AI can improve its performance with just a small number of examples. It doesn't need thousands of examples like traditional machine learning models, but it can learn effectively from just a few instances."
      ],
      "metadata": {
        "id": "5gPhwCjeshCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "def zero_shot_classification(text):\n",
        "    # configurations\n",
        "    client = genai.Client(api_key='AIzaSyCTFhlWag6uYf4i18FaT5kQvZg8oHepJQk')  # Replace with your API Key\n",
        "    model = \"gemini-2.0-flash\"\n",
        "\n",
        "    prompt = f\"Classify the following text into categories: Technology, Sports, Business, Entertainment, or Politics.\\n\\nText: {text}\\n\\nCategory:\"\n",
        "    # Call generate_content on the client object\n",
        "    response = client.models.generate_content(\n",
        "        model=model,  # Use the provided model\n",
        "        contents=[prompt]\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "# Example text for zero-shot classification\n",
        "text = \"The new iPhone features the latest advancements in mobile technology and artificial intelligence.\"\n",
        "\n",
        "# Get category without training\n",
        "category = zero_shot_classification(text)\n",
        "print(\"Predicted Category:\", category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhICU1PusgXJ",
        "outputId": "1cd0f2d2-b2dd-40a2-dfa3-f02247129284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Category: Technology\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "I want you to act as a professional E-commerce content writer. I will provide product specifications, and based on those, your task is to generate structured product descriptions in JSON format.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Carefully analyze the product specifications I provide.\n",
        "\n",
        "Extract and use key details such as SKU and Product Name.\n",
        "\n",
        "Generate exactly three product highlights, each with a maximum of 100 characters.\n",
        "\n",
        "Generate exactly three bullet points, each with a maximum of 150 characters.\n",
        "\n",
        "Ensure the output follows this strict JSON format:\n",
        "\n",
        "json\n",
        "Copy\n",
        "Edit\n",
        "{\n",
        "  \"SKU\": \"<Insert SKU here>\",\n",
        "  \"Name\": \"<Insert Product Name here>\",\n",
        "  \"Highlights\": [\n",
        "    \"<Highlight 1 (max 100 characters)>\",\n",
        "    \"<Highlight 2 (max 100 characters)>\",\n",
        "    \"<Highlight 3 (max 100 characters)>\"\n",
        "  ],\n",
        "  \"Bullet points\": [\n",
        "    \"<Bullet point 1 (max 150 characters)>\",\n",
        "    \"<Bullet point 2 (max 150 characters)>\",\n",
        "    \"<Bullet point 3 (max 150 characters)>\"\n",
        "  ]\n",
        "}\n",
        "Important:\n",
        "Only provide the JSON output. Do not include any additional commentary, explanation, or text outside the JSON structure.\n",
        "\n",
        "Product Specifications :\n",
        "\n",
        "Specifications\n",
        "Material: Fine sanded teak hard wood with waterbase finish\n",
        "Overall dimensions: 23.6\" x 19.7\" x 22.8\" (W x D x H)\n",
        "Inner dimensions: 19.7\" x 15.7\" x 19.7\" (W x D x H)\n",
        "Features ample storage space\n",
        "With stitched PE bag\n",
        "Assembly required: Yes\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=[prompt]\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "3NogFGZkYfX0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ba1c0b-5bdd-420e-92a1-506e6da76b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"SKU\": \"FW-TK-001\",\n",
            "  \"Name\": \"Teak Hardwood Storage Cabinet\",\n",
            "  \"Highlights\": [\n",
            "    \"Durable teak hardwood construction\",\n",
            "    \"Ample storage with PE bag liner\",\n",
            "    \"Stylish design for any room\"\n",
            "  ],\n",
            "  \"Bullet points\": [\n",
            "    \"Crafted from fine sanded teak hardwood with a waterbase finish for lasting beauty and durability.\",\n",
            "    \"Features a spacious interior (19.7\\\" x 15.7\\\" x 19.7\\\") and stitched PE bag for convenient storage.\",\n",
            "    \"Overall dimensions of 23.6\\\" x 19.7\\\" x 22.8\\\" provide ample storage without taking up too much space; assembly required.\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = response.usage_metadata.candidates_token_count\n",
        "input_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8Fm-Zvfw0Rj",
        "outputId": "937456c6-71e1-4491-aefa-ee5d08d8907d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokens = response.usage_metadata.prompt_token_count\n",
        "output_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2soNNaYww75L",
        "outputId": "d6ef2d2e-c850-4a03-b98c-053512ac0635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "376"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_tokens = response.usage_metadata.total_token_count\n",
        "total_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwPzG3RHxJxa",
        "outputId": "c91df70c-6fb2-4ce7-d9b6-11114be0b2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "553"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tokens = response.usage_metadata.candidates_token_count\n",
        "input_tokens_pricing = (input_tokens)/1_000_000\n",
        "input_tokens_pricing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8b4-BGsyDn7",
        "outputId": "8794db77-f098-4c06-d159-69faecc60871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000177"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pricing\n",
        "\n",
        "def pricing(input_tokens_cost, output_tokens_cost):\n",
        "  input_tokens = response.usage_metadata.candidates_token_count\n",
        "  output_tokens = response.usage_metadata.prompt_token_count\n",
        "  input_tokens_pricing = (input_tokens)/1_000_000\n",
        "  output_tokens_pricing = (output_tokens)/1_000_000\n",
        "  print(\"input_tokens_pricing : \",input_tokens_pricing)\n",
        "  print(\"output_tokens_pricing : \",output_tokens_pricing)\n",
        "  total_pricing = input_tokens_pricing*input_tokens_cost+output_tokens_pricing*output_tokens_cost\n",
        "  return total_pricing"
      ],
      "metadata": {
        "id": "8PLXQSGSxNnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing(0.10,0.40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kuaOuSExuz8",
        "outputId": "e0fd1498-2e71-40a7-b215-1f7d5218369e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_tokens_pricing :  0.000177\n",
            "output_tokens_pricing :  0.000376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0001681"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l39zGWjqfz3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To run this code you need to install the following dependencies:\n",
        "# pip install google-genai\n",
        "\n",
        "import base64\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "def generate():\n",
        "    client = genai.Client(\n",
        "        api_key=\"AIzaSyCTFhlWag6uYf4i18FaT5kQvZg8oHepJQk\",\n",
        "    )\n",
        "\n",
        "    model = \"gemini-2.0-flash\",\n",
        "\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Product Specifications :\n",
        "\n",
        "Specifications\n",
        "Material: Fine sanded teak hard wood with waterbase finish\n",
        "Overall dimensions: 23.6\\\" x 19.7\\\" x 22.8\\\" (W x D x H)\n",
        "Inner dimensions: 19.7\\\" x 15.7\\\" x 19.7\\\" (W x D x H)\n",
        "Features ample storage space\n",
        "With stitched PE bag\n",
        "Assembly required: Yes\n",
        "\n",
        "Generate product Descriptions accordingly \"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        safety_settings=[\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "                threshold=\"BLOCK_ONLY_HIGH\",  # Block few\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "                threshold=\"BLOCK_NONE\",  # Block none\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "                threshold=\"BLOCK_NONE\",  # Block none\n",
        "            ),\n",
        "            types.SafetySetting(\n",
        "                category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "                threshold=\"BLOCK_ONLY_HIGH\",  # Block few\n",
        "            ),\n",
        "        ],\n",
        "        response_mime_type=\"application/json\",\n",
        "        system_instruction=[\n",
        "            types.Part.from_text(text=\"\"\"I want you to act as a professional E-commerce content writer. I will provide product specifications, and based on those, your task is to generate structured product descriptions in JSON format.\n",
        "\n",
        "Instructions:\n",
        "\n",
        "Carefully analyze the product specifications I provide.\n",
        "\n",
        "Extract and use key details such as SKU and Product Name.\n",
        "\n",
        "Generate exactly three product highlights, each with a maximum of 100 characters.\n",
        "\n",
        "Generate exactly three bullet points, each with a maximum of 150 characters.\n",
        "\n",
        "Ensure the output follows this strict JSON format:\n",
        "\n",
        "json\n",
        "Copy\n",
        "Edit\n",
        "{\n",
        "  \\\"SKU\\\": \\\"<Insert SKU here>\\\",\n",
        "  \\\"Name\\\": \\\"<Insert Product Name here>\\\",\n",
        "  \\\"Highlights\\\": [\n",
        "    \\\"<Highlight 1 (max 100 characters)>\\\",\n",
        "    \\\"<Highlight 2 (max 100 characters)>\\\",\n",
        "    \\\"<Highlight 3 (max 100 characters)>\\\"\n",
        "  ],\n",
        "  \\\"Bullet points\\\": [\n",
        "    \\\"<Bullet point 1 (max 150 characters)>\\\",\n",
        "    \\\"<Bullet point 2 (max 150 characters)>\\\",\n",
        "    \\\"<Bullet point 3 (max 150 characters)>\\\"\n",
        "  ]\n",
        "}\n",
        "Important:\n",
        "Only provide the JSON output. Do not include any additional commentary, explanation, or text outside the JSON structure.\"\"\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        print(chunk.text, end=\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKYIo3nxvWuM",
        "outputId": "7c6a302d-5133-445b-fc18-20f49d7d2715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"SKU\": \"TK-WD-001\",\n",
            "  \"Name\": \"Teak Hard Wood Storage Box\",\n",
            "  \"Highlights\": [\n",
            "    \"Durable teak hardwood construction\",\n",
            "    \"Waterbase finish for lasting beauty\",\n",
            "    \"Ample storage space keeps items organized\"\n",
            "  ],\n",
            "  \"Bullet points\": [\n",
            "    \"Crafted from fine sanded teak hard wood ensuring durability and a natural aesthetic.\",\n",
            "    \"Features a stitched PE bag inside, providing a protective layer for your stored items.\",\n",
            "    \"Overall dimensions of 23.6\\\" x 19.7\\\" x 22.8\\\" offer a spacious yet compact storage solution.\"\n",
            "  ]\n",
            "}"
          ]
        }
      ]
    }
  ]
}
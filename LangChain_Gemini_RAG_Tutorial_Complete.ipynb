{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "52e0b3de",
      "metadata": {
        "id": "52e0b3de"
      },
      "source": [
        "# üìÇ Section 0: Setup & Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062566b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "062566b5",
        "outputId": "10b9333f-40b6-4215-f6f5-27050a2014c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.11/dist-packages (0.17.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.9.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured) (4.13.4)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.14.1)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.11/dist-packages (from unstructured) (2025.2.18)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from unstructured) (3.13.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.11/dist-packages (from unstructured) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.35.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.17.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unstructured) (5.9.5)\n",
            "Requirement already satisfied: python-oxmsg in /usr/local/lib/python3.11/dist-packages (from unstructured) (0.0.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured) (1.1)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured) (2.7)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured) (0.5.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (8.2.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured) (2024.11.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.11/dist-packages (from python-oxmsg->unstructured) (0.47)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (43.0.3)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.10\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community google-generativeai faiss-cpu unstructured pypdf langchain-google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc764d9",
      "metadata": {
        "id": "2cc764d9"
      },
      "source": [
        "\n",
        "# üìÇ Section 1: Understanding LangChain & LLM Application Architecture\n",
        "\n",
        "## What is LangChain?\n",
        "LangChain is a modular framework to build applications using Large Language Models (LLMs). It simplifies tasks like prompt management, chaining multiple actions, using agents, integrating tools, and managing memory.\n",
        "\n",
        "## Why LangChain?\n",
        "- Handles orchestration of tasks like retrieval, generation, and reasoning.\n",
        "- Pluggable architecture to work with various LLMs, vector stores, APIs, and tools.\n",
        "\n",
        "### Example: Simple Gemini LLM Call\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93b3b2e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93b3b2e",
        "outputId": "efa19ae3-d355-4a11-e31c-8c7ca226e733"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Imagine you have a super smart AI model, like ChatGPT, that can understand and generate text. But on its own, it\\'s a bit like a brain without hands. It knows a lot, but it can\\'t easily interact with the real world or use other tools.\\n\\n**LangChain is like building those hands (and other body parts!) for that AI brain.** It\\'s a framework that lets you connect a large language model (LLM) to:\\n\\n*   **External data sources:**  Think databases, websites, PDFs, etc.  This gives the LLM access to up-to-date information or specific knowledge it wasn\\'t trained on.\\n*   **Tools and utilities:**  Like a calculator, a search engine, or even an email sending program.  This allows the LLM to perform tasks beyond just generating text.\\n*   **Chains of operations:**  Allows you to link together multiple LLM calls and tools to create more complex and sophisticated workflows.\\n\\n**In short, LangChain helps you build applications that use LLMs to do more than just chat.  It helps you create intelligent agents that can:**\\n\\n*   **Answer questions based on specific documents.** (e.g., \"What\\'s the return policy on this product page?\")\\n*   **Summarize long articles or reports.**\\n*   **Automate tasks like writing emails or generating reports.**\\n*   **Build conversational bots that can access and use external information.**\\n*   **And much more!**\\n\\n**Think of it like LEGOs for AI.** LangChain provides the building blocks and the instructions to assemble powerful AI applications.\\n\\n**Key Concepts:**\\n\\n*   **LLMs:** The brain (e.g., ChatGPT, Bard, Llama).\\n*   **Data Connectors:**  Connectors to external data sources.\\n*   **Tools:** Utilities the LLM can use (e.g., search, calculator).\\n*   **Chains:** Sequences of LLM calls and tools.\\n*   **Agents:** Autonomous systems that use LLMs to decide which actions to take.\\n\\nLangChain simplifies the process of connecting these elements, making it easier for developers to build sophisticated AI-powered applications.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--f72a1bd5-612e-4672-b288-8862c3c8b228-0', usage_metadata={'input_tokens': 7, 'output_tokens': 457, 'total_tokens': 464, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=\"AIzaSyAfJRjcAoAqp-spWm0mJh5L4lHQRht1JNg\")\n",
        "llm.invoke(\"Explain LangChain in simple terms.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dfb2812",
      "metadata": {
        "id": "4dfb2812"
      },
      "source": [
        "\n",
        "# üìÇ Section 2: Components of LangChain\n",
        "\n",
        "| Component | Purpose | Example |\n",
        "|-----------|---------|---------|\n",
        "| LLM Wrappers | Interface to LLMs | Gemini, Cohere |\n",
        "| PromptTemplates | Manage dynamic prompts | Fill variables |\n",
        "| Chains | Sequential actions | Prompt ‚Üí LLM ‚Üí Output |\n",
        "| Memory | Store conversations | Chatbots |\n",
        "| Tools | External actions | Search, Calculator |\n",
        "| Agents | LLMs making decisions | Multi-tool reasoning |\n",
        "\n",
        "### Example: Using a Chain with Gemini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1671603",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1671603",
        "outputId": "e01305d7-023d-4413-8f27-aed743bb6894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-2ae1cb1dbe5b>:7: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'concept': 'Embeddings',\n",
              " 'text': 'Imagine you have a bunch of words, like \"cat\", \"dog\", \"happy\", \"sad\", \"king\", \"queen\". A computer doesn\\'t understand these words like we do. It just sees them as symbols.\\n\\n**Embeddings are a way to give these words (or other things like images or even sentences) a numerical representation that captures their meaning and relationships.**\\n\\nThink of it like this:\\n\\n* **Turning words into coordinates on a map.**\\n* **Words with similar meanings are placed closer together on the map.**\\n\\nSo, \"cat\" and \"dog\" would be closer together on the map because they are both animals. \"Happy\" and \"sad\" would be further apart because they are opposites. \"King\" and \"queen\" might be closer together because they are both related to royalty.\\n\\n**These coordinates are called \"embeddings\".** They are just lists of numbers (like [0.2, 0.8, -0.5]).\\n\\n**Why are embeddings useful?**\\n\\n* **Computers can now \"understand\" the relationships between words.**  They can do things like:\\n    * Find similar words.\\n    * Predict the next word in a sentence.\\n    * Translate languages.\\n* **They allow computers to work with text data more effectively.** Instead of just seeing symbols, they see meaningful representations.\\n\\n**In short, embeddings are a way to turn words (or other things) into numbers that capture their meaning, allowing computers to work with them in a more intelligent way.**'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "# Try importing LLMChain from the older location\n",
        "# from langchain_core.chains import LLMChain\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"Explain {concept} in easy words.\")\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "chain.invoke({\"concept\": \"Embeddings\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87c7c0e5",
      "metadata": {
        "id": "87c7c0e5"
      },
      "source": [
        "\n",
        "# üìÇ Section 3: Embeddings & Semantic Search\n",
        "\n",
        "## What are Embeddings?\n",
        "Embeddings convert text into high-dimensional vectors capturing semantic meaning. Similar meanings result in vectors close to each other in space.\n",
        "\n",
        "## Semantic Search vs Traditional Search\n",
        "- **Semantic Search**: Understands meaning and context.\n",
        "- **Traditional Search**: Relies on exact keyword matches.\n",
        "\n",
        "### Example: Gemini Embeddings with FAISS Search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7677d67b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7677d67b",
        "outputId": "2173da75-9b1f-454f-de4b-364d07d5bea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='d1074dcd-a499-4200-b943-74cc5eb58401', metadata={}, page_content='Modi is PM of India')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "texts = [\"LangChain builds LLM apps\", \"Embeddings map text to vectors\",\"Modi is PM of India\"]\n",
        "# Add the 'model' argument with a suitable embedding model name\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=\"AIzaSyAfJRjcAoAqp-spWm0mJh5L4lHQRht1JNg\")\n",
        "\n",
        "vectorstore = FAISS.from_texts(texts, embeddings)\n",
        "vectorstore.similarity_search(\"Who is PM of India?\", k=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7154f939",
      "metadata": {
        "id": "7154f939"
      },
      "source": [
        "\n",
        "# üìÇ Section 4: Loading Documents (PDF, CSV, Word)\n",
        "\n",
        "LangChain supports multiple document loaders to ingest data from various sources.\n",
        "\n",
        "## Supported Loaders\n",
        "- PDFs (PyPDFLoader, UnstructuredPDFLoader)\n",
        "- Word Docs (UnstructuredWordDocumentLoader)\n",
        "- Excel/CSV (CSVLoader, UnstructuredExcelLoader)\n",
        "\n",
        "### Example: Loading a PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d17b52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58d17b52",
        "outputId": "27183976-4bea-4084-a25c-f08a7f303216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'Skia/PDF m136', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36', 'creationdate': '2025-05-12T15:15:12+00:00', 'title': 'Python_Fundamentals.ipynb - Colab', 'moddate': '2025-05-12T15:15:12+00:00', 'source': '/content/Python_Fundamentals.ipynb - Colab.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1'}, page_content=\"Python is a high-level, general-purpose programming language known for its:\\nReadability: Syntax resembles plain English, making it beginner-friendly.\\nVersatility: Applicable to various domains like web development, data science, machine\\nlearning, and automation.\\nLarge Standard Library: Rich collection of built-in modules and functions for diverse tasks.\\nOpen-Source Community: Extensive support and contributions from a vast developer\\ncommunity.\\nKey Features of Python:\\nInterpreted Language: Code is executed line by line without prior compilation, offering\\nfaster development cycles.\\nDynamic Typing: No need to explicitly declare variable data types. Python infers types\\nbased on assigned values.\\nObject-Oriented Programming (OOP): Supports object-oriented concepts like classes,\\nobjects, inheritance, and polymorphism for code organization and reusability.\\nStrong Libraries and Frameworks: Abundant third-party libraries and frameworks extend\\nPython's capabilities for specific domains.\\nCross-Platform: Python code runs on various operating systems (Windows, macOS, Linux)\\nwithout major modifications.\\nImportance of Python for Data Science:\\nData Analysis: Libraries like NumPy and Pandas provide powerful data structures and\\ntools for efficient data manipulation and analysis.\\nMachine Learning: Frameworks like TensorFlow and scikit-learn offer comprehensive\\nlibraries for building and deploying machine learning models.\\nData Visualization: Libraries like Matplotlib and Seaborn create informative visualizations\\nto explore and communicate data insights.\\nAutomation: Python scripts can automate data cleaning, preprocessing, and model\\ntraining tasks, saving time and effort.\\nIn Summary:\\nPython's combination of readability, versatility, and rich ecosystem of libraries makes it a\\ncompelling choice for data science tasks.\\nIts user-friendly nature allows beginners to grasp the fundamentals quickly, while its power\\ncaters to complex data analysis and machine learning applications.\\nWhat is Python?\\ue313\\n5/12/25, 8:45 PM Python_Fundamentals.ipynb - Colab\\nhttps://colab.research.google.com/drive/1u5zBzLZmTve9h7oB0IimyHnxPyeKTeYd#printMode=true 1/30\")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Python_Fundamentals.ipynb - Colab.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "# View first document chunk\n",
        "documents[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c0e896",
      "metadata": {
        "id": "d4c0e896"
      },
      "source": [
        "\n",
        "# üìÇ Section 5: Chunking & Storing Embeddings\n",
        "\n",
        "## Why Chunking?\n",
        "- LLMs have token limits.\n",
        "- Chunking breaks large documents into manageable parts.\n",
        "\n",
        "### Example: Chunking Documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6ffc33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e6ffc33",
        "outputId": "4ac4a915-a06e-4603-d766-23c135180356"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'Skia/PDF m136', 'creator': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36', 'creationdate': '2025-05-12T15:15:12+00:00', 'title': 'Python_Fundamentals.ipynb - Colab', 'moddate': '2025-05-12T15:15:12+00:00', 'source': '/content/Python_Fundamentals.ipynb - Colab.pdf', 'total_pages': 30, 'page': 0, 'page_label': '1'}, page_content='Python is a high-level, general-purpose programming language known for its:\\nReadability: Syntax resembles plain English, making it beginner-friendly.\\nVersatility: Applicable to various domains like web development, data science, machine\\nlearning, and automation.\\nLarge Standard Library: Rich collection of built-in modules and functions for diverse tasks.\\nOpen-Source Community: Extensive support and contributions from a vast developer\\ncommunity.\\nKey Features of Python:')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# View chunked document\n",
        "chunks[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f8afaa",
      "metadata": {
        "id": "74f8afaa"
      },
      "source": [
        "\n",
        "### Storing Chunks as Embeddings in FAISS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48483ff0",
      "metadata": {
        "id": "48483ff0"
      },
      "outputs": [],
      "source": [
        "\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b215eb46",
      "metadata": {
        "id": "b215eb46"
      },
      "source": [
        "\n",
        "# üìÇ Section 7: Memory in LangChain\n",
        "\n",
        "## What is Memory?\n",
        "Memory stores previous interactions to enable context-aware conversations.\n",
        "\n",
        "## Types of Memory\n",
        "- ConversationBufferMemory\n",
        "- ConversationSummaryMemory\n",
        "- ConversationBufferWindowMemory\n",
        "\n",
        "### Example: Using ConversationBufferMemory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dda2dca0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dda2dca0",
        "outputId": "cbf199c2-34b0-43d4-db34-9b65b733fe29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c17ff5d70484>:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "<ipython-input-15-c17ff5d70484>:6: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(llm=llm, memory=memory)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What did I just ask you?',\n",
              " 'history': \"Human: Hello, who are you?\\nAI: Hello! I am a large language model, trained by Google. I'm designed to be informative and comprehensive. I can communicate and generate human-like text in response to a wide range of prompts and questions. For example, I can provide summaries of factual topics, create stories, and translate languages.\\n\\nI'm still under development, which means I'm constantly learning and being improved. My knowledge is based on the massive dataset of text and code that I was trained on. I can't access information in real time, so my knowledge is limited to what was available in that dataset up to a certain point in time. I can't tell you exactly *when* that point is, as that's proprietary information, but I can say it's not happening *right now* - I'm not actively browsing the web or anything like that! I'm just using the information I've already learned.\\n\\nIs there anything specific you'd like to know or anything I can help you with? I'm eager to show you what I can do!\",\n",
              " 'response': 'You just asked me \"What did I just ask you?\". That\\'s a fun question! It\\'s like a little loop. I recognized that you were asking me to recall your previous question. Pretty neat, huh? What else can I remember for you?'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "# Changed import path for ConversationChain\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "conversation.invoke({\"input\": \"Hello, who are you?\"})\n",
        "conversation.invoke({\"input\": \"What did I just ask you?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0aa688",
      "metadata": {
        "id": "7b0aa688"
      },
      "source": [
        "\n",
        "# üìÇ Section 8: Tools Integration & Real-time Search\n",
        "\n",
        "LangChain Agents can use external tools (e.g., Search, Calculator) to ground LLM responses.\n",
        "\n",
        "### Example: Adding a Search Tool (DuckDuckGo)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo-search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDZxqGF-3kNd",
        "outputId": "bcfbeff6-1dcf-48dc-ddd7-c98b01287c50"
      },
      "id": "JDZxqGF-3kNd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-8.0.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.2.0)\n",
            "Collecting primp>=0.15.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.4.0)\n",
            "Downloading duckduckgo_search-8.0.2-py3-none-any.whl (18 kB)\n",
            "Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-8.0.2 primp-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5416ba02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5416ba02",
        "outputId": "c6fa954f-8b9b-482b-849a-401c8404be02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is Operation Sindoor?',\n",
              " 'output': 'Operation Sindoor was a military operation launched by India against Pakistan in May 2025, involving missile strikes in response to a terrorist attack in Pahalgam.'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "from langchain.tools.ddg_search import DuckDuckGoSearchRun\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "tools = [search]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
        "\n",
        "agent.invoke(\"What is Operation Sindoor?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "239bea85",
      "metadata": {
        "id": "239bea85"
      },
      "source": [
        "\n",
        "# üìÇ Section 9: Building a RAG Pipeline with Gemini\n",
        "\n",
        "### Steps:\n",
        "1. Load documents\n",
        "2. Chunk documents\n",
        "3. Embed & store in vector DB\n",
        "4. Retrieve relevant chunks\n",
        "5. Combine with LLM to answer queries\n",
        "\n",
        "### Example: Simple RAG Flow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87369be1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87369be1",
        "outputId": "0ed930f8-1d7e-4620-b87c-0c6363292bfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'What are the features of Python?',\n",
              " 'result': \"Here's a summary of Python's key features:\\n\\n*   **Readability:** Python's syntax is similar to plain English, making it easy to learn and understand.\\n*   **Versatility:** It can be used in many different fields like web development, data science, machine learning, and automation.\\n*   **Interpreted Language:** Python code is executed line by line, allowing for faster development.\\n*   **Dynamic Typing:** You don't need to declare variable types explicitly.\\n*   **Object-Oriented Programming (OOP):** Supports concepts like classes, objects, inheritance, and polymorphism.\\n*   **Large Standard Library:** It has a rich collection of built-in modules and functions.\\n*   **Strong Libraries and Frameworks:** Many third-party libraries and frameworks extend Python's capabilities.\\n*   **Cross-Platform:** Python code can run on different operating systems without major changes.\\n*   **Open-Source Community:** It has extensive support and contributions from a large developer community.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "rag_chain.invoke({\"query\": \"What are the features of Python?\"})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5245b195",
      "metadata": {
        "id": "5245b195"
      },
      "source": [
        "\n",
        "# üìÇ Section 10: Capstone Project ‚Äî Build a RAG Chatbot\n",
        "\n",
        "### Goal:\n",
        "Build a chatbot that can answer questions from uploaded PDF/CSV/Word files using Gemini LLM.\n",
        "\n",
        "### Steps:\n",
        "1. Upload a document (PDF/CSV/Word).\n",
        "2. Load, Chunk & Embed it.\n",
        "3. Store in FAISS index.\n",
        "4. Use RetrievalQA Chain for querying.\n",
        "\n",
        "### Code Template (Reusable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f81437",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5f81437",
        "outputId": "479632ce-a329-471f-c082-62d13298a2b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How for loop works.?',\n",
              " 'result': 'The for loop iterates over a sequence of elements (list, tuple, string). The variable element takes on the value of each item in the sequence during each iteration.'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "\n",
        "# Load your document (example: PDF)\n",
        "loader = PyPDFLoader(\"/content/Python_Fundamentals.ipynb - Colab.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Chunking\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# Embedding & Storing\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Building RAG Chatbot\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "rag_chain.invoke({\"query\": \"How for loop works.?\"})\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}